@inproceedings{He2016,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={IEEE conference on computer vision and pattern recognition (CVPR)},
	pages={770--778},
	year={2016}
}

@misc{Vinyals2019,
	title="{AlphaStar: Mastering the Real-Time Strategy Game StarCraft II}",
	author={Vinyals, Oriol and Babuschkin, Igor and Chung, Junyoung and Mathieu, Michael and Jaderberg, Max and Czarnecki, Wojciech M. and Dudzik, Andrew and Huang, Aja and Georgiev, Petko and Powell, Richard and Ewalds, Timo and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Agapiou, John and Oh, Junhyuk and Dalibard, Valentin and Choi, David and Sifre, Laurent and Sulsky, Yury and Vezhnevets, Sasha and Molloy, James and Cai, Trevor and Budden, David and Paine, Tom and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Pohlen, Toby and Wu, Yuhuai and Yogatama, Dani and Cohen, Julia and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Apps, Chris and Kavukcuoglu, Koray and Hassabis, Demis and Silver, David},
	howpublished={\url{https://deepmind.com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii/}},
	year={2019}
}

@inproceedings{Krizhevsky2012,
	title={Imagenet classification with deep convolutional neural networks},
	author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	booktitle={Conference on Neural Information Processing Systems (NIPS)},
	pages={1097--1105},
	year={2012}
}

@inproceedings{Winter1988,
	title={Madaline Rule II: a training algorithm for neural networks},
	author={Winter, R and Widrow, B},
	booktitle={IEEE International Conference on Neural Networks},
	pages={1--401},
	year={1988}
}

@book{Minsky2017,
	title={Perceptrons: An introduction to computational geometry},
	author={Minsky, Marvin and Papert, Seymour A},
	year={2017},
	publisher={MIT press}
}

@ARTICLE{Rosenblatt1958,
	author = {F. Rosenblatt},
	title = {The Perceptron: A Probabilistic Model for Information Storage and Organization in The Brain},
	journal = {Psychological Review},
	year = {1958},
	pages = {65--386}
}

@article{McCarthy2006,
	author = {McCarthy, John and Minsky, Marvin L. and Rochester, Nathaniel and Shannon, Claude E.},
	issn = {2371-9621},
	journal = {AI Magazine},
	month = {dec},
	number = {4},
	pages = {12--12},
	title = {{A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence, August 31, 1955}},
	volume = {27},
	year = {2006}
}


@Article{McCulloch1943,
	author="McCulloch, Warren S. and Pitts, Walter",
	title="A logical calculus of the ideas immanent in nervous activity",
	journal="The bulletin of mathematical biophysics",
	year="1943",
	month="Dec",
	day="01",
	volume="5",
	number="4",
	pages="115--133",
	issn="1522-9602",
}

@inproceedings{Hessel2018,
	title={Rainbow: Combining improvements in deep reinforcement learning},
	author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
	booktitle={AAAI Conference on Artificial Intelligence},
	year={2018}
	}
	@misc{OpenAI2017,
	author = {OpenAI},
	title = {{OpenAI Baselines: ACKTR {\&} A2C}},
	url = {https://blog.openai.com/baselines-acktr-a2c/},
	urldate = {2019-03-02},
	year = {2017}
}

@inproceedings{Mnih2016,
	title={Asynchronous methods for deep reinforcement learning},
	author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
	booktitle={International conference on machine learning (ICML)},
	pages={1928--1937},
	year={2016}
}

@article{Silver2017a,
	author = {Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and Chen, Yutian and Lillicrap, Timothy and Hui, Fan and Sifre, Laurent and van den Driessche, George and Graepel, Thore and Hassabis, Demis},
	issn = {0028-0836},
	journal = {Nature},
	keywords = {Computational science,Computer science,Reward},
	month = {oct},
	number = {7676},
	pages = {354--359},
	publisher = {Nature Publishing Group},
	title = {{Mastering the game of Go without human knowledge}},
	volume = {550},
	year = {2017}
}
@incollection{Munos2016,
	author = {Munos, Remi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
	booktitle = {Conference on Neural Information Processing Systems (NIPS)},
	pages = {1054--1062},
	title = {{Safe and Efficient Off-Policy Reinforcement Learning}},
	year = {2016}
}
@inproceedings{VanSeijen2009,
	author = {van Seijen, H and van Hasselt, H and Whiteson, S and Wiering, M},
	booktitle = {IEEE Symposium on Adaptive Dynamic Programming and Reinforcement Learning (ADPRL)},
	issn = {2325-1824},
	pages = {177--184},
	title = {{A theoretical and empirical analysis of Expected Sarsa}},
	year = {2009}
}
@article{Tesauro1994,
	author = {Tesauro, Gerald},
	isbn = {978-1-4757-2379-3},
	journal = {Applications of Neural Networks},
	number = {2},
	pages = {215--219},
	title = {{TD-Gammon, a Self-Teaching Backgammon Program, Achieves Master-Level Play}},
	volume = {6},
	year = {1994}
}
@inproceedings{Schulman2015a,
	archivePrefix = {arXiv},
	arxivId = {1506.02438},
	author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
	booktitle = {International Conference on Learning Representations (ICLR)},
	eprint = {1506.02438},
	month = {jun},
	title = {{High-Dimensional Continuous Control Using Generalized Advantage Estimation}},
	year = {2015}
}
@inproceedings{Kakade2002,
	author = {Kakade, Sham M},
	booktitle = {Advances in neural information processing systems},
	pages = {1531--1538},
	title = {{A natural policy gradient}},
	year = {2002}
}

@article{Mnih2015,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
	journal = {Nature},
	keywords = {Computer science},
	number = {7540},
	pages = {529--533},
	title = {{Human-level control through deep reinforcement learning}},
	volume = {518},
	year = {2015}
}
@inproceedings{Schulman2015,
	author = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
	booktitle = {International Conference on Machine Learning (ICML)},
	pages = {1889--1897},
	title = {{Trust Region Policy Optimization}},
	volume = {37},
	year = {2015}
}

@inproceedings{Lillicrap2016,
	author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
	booktitle = {International Conference on Learning Representations (ICLR)},
	month = {sep},
	title = {{Continuous control with deep reinforcement learning}},
	year = {2016}
}

@inproceedings{Schaul2015,
	author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	booktitle = {International Conference for Learning Representations (ICLR)},
	title = {{Prioritized Experience Replay}},
	journal={arXiv preprint arXiv:1511.05952},
	year = {2015}
}

@article{Babaeizadeh2017,
	author = {Babaeizadeh, Mohammad and Frosio, Iuri and Tyree, Stephen and Clemons, Jason and Kautz, Jan},
	title = {{Reinforcement Learning through Asynchronous Advantage Actor-Critic on a GPU}},
	year = {2017}
}

@article{Abdolmaleki2018,
	author = {Abdolmaleki, Abbas and Springenberg, Jost Tobias and Tassa, Yuval and Munos, Remi and Heess, Nicolas and Riedmiller, Martin},
	title = {{Maximum a Posteriori Policy Optimisation}},
	journal={arXiv preprint arXiv:1806.06920},
	year = {2018}
}
@inproceedings{Haarnoja2017,
	booktitle = {International Conference on Machine Learning (ICML)},
	author = {Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
	pages     = {1352--1361},
	title = {{Reinforcement Learning with Deep Energy-Based Policies}},
	year = {2017}
}

@article {Silver2017,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	journal = {Science}
}

@inproceedings{Silver2014,
	author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
	booktitle = {International Conference on Machine Learning (ICML)},
	pages={387--395},
	title = {{Deterministic Policy Gradient Algorithms}},
	year = {2014}
}

@article{Gruslys2017,
	author = {Gruslys, Audrunas and Dabney, Will and Azar, Mohammad Gheshlaghi and Piot, Bilal and Bellemare, Marc and Munos, Remi},
	title = {{The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning}},
	year = {2017}
}

@incollection{Hausknecht2015,
	author = {Hausknecht, Matthew and Stone, Peter},
	booktitle = {AAAI Fall Symposia},
	title = {{Deep Recurrent Q-Learning for Partially Observable MDPs}},
	year = {2015}
}

@inproceedings{Todorov2005,
	author = {Todorov, E and Li, Weiwei},
	booktitle = {American Control Conference},
	month = {jun},
	pages = {300--306},
	title = {{A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems}},
	year = {2005}
}

@article{Jaderberg2016,
	author = {Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
	title = {{Reinforcement Learning with Unsupervised Auxiliary Tasks}},
	year = {2016}
}

@inproceedings{Haarnoja2018,
	author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
	booktitle = {International Conference for Machine Learning (ICML)},
	title = {{Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor}},
	year = {2018}
}
@inproceedings{Gu2016,
	author = {Gu, Shixiang and Lillicrap, Timothy and Sutskever, Ilya and Levine, Sergey},
	booktitle = {International Conference on Machine Learning (ICML)},
	pages = {2829--2838},
	title = {{Continuous Deep Q-Learning with Model-based Acceleration}},
	year = {2016}

@inproceedings{Jouppi2017,
	author = {Jouppi, Norman P and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and Boyle, Rick and Cantin, Pierre-luc and Chao, Clifford and Clark, Chris and Coriell, Jeremy and Daley, Mike and Dau, Matt and Dean, Jeffrey and Gelb, Ben and Ghaemmaghami, Tara Vazir and Gottipati, Rajendra and Gulland, William and Hagmann, Robert and Ho, C Richard and Hogberg, Doug and Hu, John and Hundt, Robert and Hurt, Dan and Ibarz, Julian and Jaffey, Aaron and Jaworski, Alek and Kaplan, Alexander and Khaitan, Harshit and Killebrew, Daniel and Koch, Andy and Kumar, Naveen and Lacy, Steve and Laudon, James and Law, James and Le, Diemthu and Leary, Chris and Liu, Zhuyuan and Lucke, Kyle and Lundin, Alan and MacKean, Gordon and Maggiore, Adriana and Mahony, Maire and Miller, Kieran and Nagarajan, Rahul and Narayanaswami, Ravi and Ni, Ray and Nix, Kathy and Norrie, Thomas and Omernick, Mark and Penukonda, Narayana and Phelps, Andy and Ross, Jonathan and Ross, Matt and Salek, Amir and Samadiani, Emad and Severn, Chris and Sizikov, Gregory and Snelham, Matthew and Souter, Jed and Steinberg, Dan and Swing, Andy and Tan, Mercedes and Thorson, Gregory and Tian, Bo and Toma, Horia and Tuttle, Erick and Vasudevan, Vijay and Walter, Richard and Wang, Walter and Wilcox, Eric and Yoon, Doe Hyun},
	booktitle = {International Symposium on Computer Architecture (ISCA)},
	pages = {1--12},
	title = {{In-Datacenter Performance Analysis of a Tensor Processing Unit}},
	year = {2017}
}

@inproceedings{Riedmiller1993,
	author = {Riedmiller, Martin and Braun, Heinrich},
	booktitle = {IEEE International Conference on Neural Networks},
	pages = {586--591},
	title = {{A Direct Adaptive Method for Faster Backpropagation Learning: The RPROP Algorithm}},
	year = {1993}
}

@article{Vinyals2017,
	author = {Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"{u}}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and Quan, John and Gaffney, Stephen and Petersen, Stig and Simonyan, Karen and Schaul, Tom and van Hasselt, Hado and Silver, David and Lillicrap, Timothy and Calderone, Kevin and Keet, Paul and Brunasso, Anthony and Lawrence, David and Ekermo, Anders and Repp, Jacob and Tsing, Rodney},
	title = {{StarCraft II: A New Challenge for Reinforcement Learning}},
	year = {2017}
}

@article{Silver2016,
	author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
	journal = {Nature},
	number = {7587},
	pages = {484--489},
	title = {{Mastering the game of Go with deep neural networks and tree search}},
	volume = {529},
	year = {2016}
}

@inproceedings{Barth-Maron2018,
	author = {Barth-Maron, Gabriel and Hoffman, Matthew W. and Budden, David and Dabney, Will and Horgan, Dan and TB, Dhruva and Muldal, Alistair and Heess, Nicolas and Lillicrap, Timothy},
	booktitle = {International Conference on Learning Representations (ICLR)},
	title = {{Distributed Distributional Deterministic Policy Gradients}},
	year = {2018}
}

@book{Bellman1957,
	author = {Bellman, Richard},
	isbn = {9780486428093},
	publisher = {Dover Publications},
	title = {{Dynamic Programming}},
	year = {1957}
}

@article{Heess2017,
	author = {Heess, Nicolas and TB, Dhruva and Sriram, Srinivasan and Lemmon, Jay and Merel, Josh and Wayne, Greg and Tassa, Yuval and Erez, Tom and Wang, Ziyu and Eslami, S. M. Ali and Riedmiller, Martin and Silver, David},
	title = {{Emergence of Locomotion Behaviours in Rich Environments}},
	year = {2017}
}

@misc{OpenAI2018,
	author = {OpenAI},
	title = {OpenAI Five},
	howpublished = {\url{https://blog.openai.com/openai-five/}}
	year = {2018}
}

@incollection{VanHasselt2010,
	author = {van Hasselt, Hado},
	booktitle = {Conference on Neural Information Processing Systems (NIPS)},
	pages = {2613--2621},
	title = {{Double Q-learning}},
	year = {2010}
}

@inproceedings{Pollack1997a,
	author = {Pollack, Jordan B and Blair, Alan D},
	booktitle = {Conference on Neural Information Processing Systems (NIPS)},
	pages = {10--16},
	title = {{Why did TD-gammon work?}},
	year = {1997}
}

@phdthesis{Watkins1989,
	author = {Watkins, Christopher John Cornish Hellaby},
	school = {King's College, Cambridge},
	title = {{Learning from delayed rewards}},
	year = {1989}
}

@inproceedings{Bellemare2017,
	author = {Bellemare, Marc G. and Dabney, Will and Munos, R{\'{e}}mi},
	booktitle = {International Conference for Machine Learning (ICML)},
	title = {{A Distributional Perspective on Reinforcement Learning}},
	year = {2017}
}

@inproceedings{Kakade2001,
	author = {Kakade, Sham},
	booktitle = {Conference on Neural Information Processing Systems (NIPS)},
	pages = {1531--1538},
	title = {{A Natural Policy Gradient}},
	year = {2001}
}
@article{Bellemare2013,
	author = {Bellemare, M. G. and Naddaf, Y. and Veness, J. and Bowling, M.},
	journal = {Journal of Artificial Intelligence Research},
	pages = {253--279},
	title = {{The Arcade Learning Environment: An Evaluation Platform for General Agents}},
	volume = {47},
	year = {2013}
}

@article{Sun2018,
	author = {Sun, Peng and Sun, Xinghai and Han, Lei and Xiong, Jiechao and Wang, Qing and Li, Bo and Zheng, Yang and Liu, Ji and Liu, Yongsheng and Liu, Han and Zhang, Tong},
	month = {sep},
	title = {{TStarBots: Defeating the Cheating Level Builtin AI in StarCraft II in the Full Game}},
	year = {2018}
}

@article{Peters2008,
	author = {Peters, Jan and Schaal, Stefan},
	journal = {Neurocomputing},
	number = {7-9},
	pages = {1180--1190},
	title = {{Natural actor-critic}},
	volume = {71},
	year = {2008}
}

@incollection{Kulkarni2016,
	author = {Kulkarni, Tejas D and Narasimhan, Karthik and Saeedi, Ardavan and Tenenbaum, Josh},
	booktitle = {Conference on Neural Information Processing Systems (NIPS)},
	pages = {3675--3683},
	title = {{Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation}},
	year = {2016}
}
@inproceedings{Wang2016,
	author = {Wang, Ziyu and Schaul, Tom and Hessel, Matteo and {Van Hasselt}, Hado and Lanctot, Marc and {De Freitas}, Nando},
	booktitle = {International Conference on Machine Learning (ICML)},
	pages = {1995--2003},
	title = {{Dueling Network Architectures for Deep Reinforcement Learning}},
	year = {2016}
}
@inproceedings{Grosse2016,
	author = {Grosse, Roger and Martens, James},
	booktitle = {International Conference on Machine Learning (ICML)},
	pages = {573--582},
	title = {{A Kronecker-factored Approximate Fisher Matrix for Convolution Layers}},
	year = {2016}
}
@book{Sutton2018,
	address = {Cambridge, MA},
	author = {Sutton, Richard S and Barto, Andrew G},
	edition = {Second Edition},
	publisher = {MIT Press},
	title = {{Reinforcement learning: An introduction}},
	year = {2018}
}
@inproceedings{Sutton1990,
	author = {Sutton, Richard S},
	booktitle = {International Conference for Machine Learning (ICML)},
	pages = {216--224},
	title = {{Integrated architectures for learning, planning, reacting based on approxmiate dynmaic programming}},
	year = {1990}
}
@inproceedings{McAleer2018,
	author = {McAleer, Stephen and Agostinelli, Forest and Shmakov, Alexander and Baldi, Pierre},
	booktitle = {Conference on Neural Information Processing Systems (NIPS)},
	title = {{Solving the Rubik's Cube Without Human Knowledge}},
	year = {2018}
}

@incollection{Wu2017,
	author = {Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
	booktitle = {Conference on Neural Information Processing Systems (NIPS)},
	pages = {5279--5288},
	title = {{Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation}},
	year = {2017}
}

@inproceedings{Wang2017,
	author = {Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
	booktitle = {International Conference on Learning Representations (ICLR)},
	title = {{Sample Efficient Actor-Critic with Experience Replay}},
	year = {2017}
}

@article{Mnih2013,
	author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
	journal = {NIPS Deep Learning Workshop},
	title = {{Playing Atari with Deep Reinforcement Learning}},
	url = {http://arxiv.org/abs/1312.5602},
	year = {2013}
}

@article{Schulman2017,
	author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	title = {{Proximal Policy Optimization Algorithms}},
	year = {2017}
}

@inproceedings{Schulze2018,
	author = {Schulze, Christopher and Schulze, Marcus},
	booktitle = {Intelligent Systems and Applications},
	pages = {1--17},
	title = {{ViZDoom: DRQN with Prioritized Experience Replay, Double-Q Learning and Snapshot Ensembling}},
	year = {2018}
}

@inproceedings{VanHasselt2016,
	author = {van Hasselt, Hado and Guez, Arthur and Silver, David},
	booktitle = {AAAI Conference on Artificial Intelligence},
	pages = {2094--2100},
	title = {{Deep Reinforcement Learning with Double Q-learning}},
	year = {2016}
}
@inproceedings{Martens2015,
	title = {{Optimizing Neural Networks with Kronecker-factored Approximate Curvature}},
	author={Martens, James and Grosse, Roger},
	booktitle={International conference on machine learning (ICML)},
	pages={2408--2417},
	year={2015}
}

@inproceedings{Riedmiller2005,
	author = {Riedmiller, Martin},
	booktitle={European Conference on Machine Learning (ECML)},
	pages = {317--328},
	title = {{Neural Fitted Q Iteration - First Experiences with a Data Efficient Neural Reinforcement Learning Method}},
	year = {2005}
}

@inproceedings{Fujimoto2018,
	author = {Fujimoto, Scott and van Hoof, Herke and Meger, David},
	booktitle = {International Conference for Machine Learning (ICML)},
	title = {{Addressing Function Approximation Error in Actor-Critic Methods}},
	pages = {1582--1591},	
	year = {2018}
}

@incollection{Lowe2017,
	annote = {MADDPG base paper},
	author = {Lowe, Ryan and WU, Y I and Tamar, Aviv and Harb, Jean and {Pieter Abbeel}, OpenAI and Mordatch, Igor},
	booktitle = {Conference on Neural Information Processing Systems (NIPS)},
	pages = {6379--6390},
	title = {{Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments}},
	year = {2017}
}

@article{Lin1992,
	author = {Lin, Long-Ji},
	journal = {Machine Learning},
	number = {3},
	pages = {293--321},
	title = {{Self-improving reactive agents based on reinforcement learning, planning and teaching}},
	volume = {8},
	year = {1992}
}
@article{Hunter2004,
	author = {Hunter, David R and Lange, Kenneth},
	journal = {The American Statistician},
	number = {1},
	pages = {30--37},
	title = {{A tutorial on MM algorithms}},
	volume = {58},
	year = {2004}
}
@article{Williams1992,
	author = {Williams, Ronald J},
	journal = {Machine Learning},
	number = {3},
	pages = {229--256},
	title = {{Simple statistical gradient-following algorithms for connectionist reinforcement learning}},
	volume = {8},
	year = {1992}

@inproceedings{Ioffe2015,
	author = {Ioffe, Sergey and Szegedy, Christian},
	booktitle = {International Conference on Machine Learning (ICML)},
	pages = {448--456},
	title = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
	year = {2015}
}